models:
  - name: "bge-m3"
    handler: "app.models.bge_m3.BgeM3Embedding"
    hf_repo_id: "BAAI/bge-m3"
  - name: "embedding-gemma-300m"
    handler: "app.models.embedding_gemma.EmbeddingGemmaEmbedding"
    hf_repo_id: "google/embeddinggemma-300m"
  - name: "qwen3-vl-4b-instruct-fp8"
    handler: "app.models.qwen_vl.QwenVLChat"
    hf_repo_id: "Qwen/Qwen3-VL-4B-Instruct-FP8"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "qwen3-vl-2b-instruct-fp8"
    handler: "app.models.qwen_vl.QwenVLChat"
    hf_repo_id: "Qwen/Qwen3-VL-2B-Instruct-FP8"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "qwen3-vl-4b-instruct"
    handler: "app.models.qwen_vl.QwenVLChat"
    hf_repo_id: "Qwen/Qwen3-VL-4B-Instruct"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "qwen3-vl-2b-instruct"
    handler: "app.models.qwen_vl.QwenVLChat"
    hf_repo_id: "Qwen/Qwen3-VL-2B-Instruct"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "qwen3-4b-instruct-2507"
    handler: "app.models.text_chat.TextChatModel"
    hf_repo_id: "Qwen/Qwen3-4B-Instruct-2507"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "qwen3-4b-instruct-2507-fp8"
    handler: "app.models.text_chat.TextChatModel"
    hf_repo_id: "Qwen/Qwen3-4B-Instruct-2507-FP8"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "llama-3.2-1b-instruct"
    handler: "app.models.text_chat.TextChatModel"
    hf_repo_id: "meta-llama/Llama-3.2-1B-Instruct"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
  - name: "llama-3.2-3b-instruct"
    handler: "app.models.text_chat.TextChatModel"
    hf_repo_id: "meta-llama/Llama-3.2-3B-Instruct"
    defaults:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 512
